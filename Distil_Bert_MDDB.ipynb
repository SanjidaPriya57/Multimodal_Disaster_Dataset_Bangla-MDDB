{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11135603,"sourceType":"datasetVersion","datasetId":6945370}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip list | grep \"torch\\|tensorflow\\|transformers\\|opencv\\|scikit-learn\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:39.966049Z","iopub.execute_input":"2025-03-24T11:12:39.966363Z","iopub.status.idle":"2025-03-24T11:12:41.992624Z","shell.execute_reply.started":"2025-03-24T11:12:39.966339Z","shell.execute_reply":"2025-03-24T11:12:41.991819Z"}},"outputs":[{"name":"stdout","text":"opencv-contrib-python              4.10.0.84\nopencv-python                      4.10.0.84\nopencv-python-headless             4.10.0.84\npytorch-ignite                     0.5.1\npytorch-lightning                  2.5.0.post0\nscikit-learn                       1.2.2\nscikit-learn-intelex               2025.2.0\nsentence-transformers              3.3.1\ntensorflow                         2.17.1\ntensorflow-cloud                   0.1.5\ntensorflow-datasets                4.9.7\ntensorflow_decision_forests        1.10.0\ntensorflow-hub                     0.16.1\ntensorflow-io                      0.37.1\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.13.1\ntensorflow-probability             0.24.0\ntensorflow-text                    2.17.0\ntorch                              2.5.1+cu121\ntorchaudio                         2.5.1+cu121\ntorchinfo                          1.8.0\ntorchmetrics                       1.6.1\ntorchsummary                       1.5.1\ntorchtune                          0.5.0\ntorchvision                        0.20.1+cu121\ntransformers                       4.47.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torch torchvision transformers opencv-python scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:41.993581Z","iopub.execute_input":"2025-03-24T11:12:41.993828Z","iopub.status.idle":"2025-03-24T11:12:45.674384Z","shell.execute_reply.started":"2025-03-24T11:12:41.993805Z","shell.execute_reply":"2025-03-24T11:12:45.673558Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ncsv_path = '/kaggle/input/multimodal-disaster-dataset-bangla/Multimodal Disaster Bangla Dataset/Thesis.csv'\ndf = pd.read_csv(csv_path,encoding=\"utf-8\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:45.675383Z","iopub.execute_input":"2025-03-24T11:12:45.675673Z","iopub.status.idle":"2025-03-24T11:12:46.046957Z","shell.execute_reply.started":"2025-03-24T11:12:45.675635Z","shell.execute_reply":"2025-03-24T11:12:46.046122Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"    id                                            caption  label  level  \\\n0    1  ‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...  flood      1   \n1    2  ‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...  flood      1   \n2    3                                           ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ  flood      1   \n3    4  ‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ ‡¶ì ‡¶ï‡¶∏‡¶¨‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ'‡¶∞ ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡ßü ‡¶á...  flood      1   \n4    5  ‡¶´‡ßá‡¶®‡ßÄ‡¶∞ ‡¶Æ‡ßÅ‡¶π‡ßÅ‡¶∞‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶§‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶ó‡¶§ ‡ß™‡ß¶ ‡¶¨‡¶õ‡¶∞‡ßá‡¶∞ ‡¶á‡¶§...  flood      1   \n\n       area Unnamed: 5  \n0  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n1  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n2  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n3   ‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ         NaN  \n4      ‡¶´‡ßá‡¶®‡ßÄ        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>caption</th>\n      <th>label</th>\n      <th>level</th>\n      <th>area</th>\n      <th>Unnamed: 5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ ‡¶ì ‡¶ï‡¶∏‡¶¨‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ'‡¶∞ ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡ßü ‡¶á...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>‡¶´‡ßá‡¶®‡ßÄ‡¶∞ ‡¶Æ‡ßÅ‡¶π‡ßÅ‡¶∞‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶§‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶ó‡¶§ ‡ß™‡ß¶ ‡¶¨‡¶õ‡¶∞‡ßá‡¶∞ ‡¶á‡¶§...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶´‡ßá‡¶®‡ßÄ</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:46.047648Z","iopub.execute_input":"2025-03-24T11:12:46.047919Z","iopub.status.idle":"2025-03-24T11:12:53.566918Z","shell.execute_reply.started":"2025-03-24T11:12:46.047897Z","shell.execute_reply":"2025-03-24T11:12:53.566254Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Drop unnecessary columns if they exist\ncolumns_to_drop = [col for col in ['label', 'area', 'Unnamed: 5'] if col in df.columns]\ndf = df.drop(columns_to_drop, axis=1)\n\n# Shuffle the dataframe\ndf = shuffle(df, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:53.567571Z","iopub.execute_input":"2025-03-24T11:12:53.567936Z","iopub.status.idle":"2025-03-24T11:12:53.580105Z","shell.execute_reply.started":"2025-03-24T11:12:53.567913Z","shell.execute_reply":"2025-03-24T11:12:53.579253Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Split the dataset\ntrain_ratio = 0.6\nval_ratio = 0.2\ntest_ratio = 0.2\n\ntrain_data, val_test = train_test_split(df, train_size=train_ratio, random_state=42)\nvalid_data, test_data = train_test_split(val_test, train_size=val_ratio / (val_ratio + test_ratio), random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:53.582097Z","iopub.execute_input":"2025-03-24T11:12:53.582290Z","iopub.status.idle":"2025-03-24T11:12:53.654058Z","shell.execute_reply.started":"2025-03-24T11:12:53.582273Z","shell.execute_reply":"2025-03-24T11:12:53.653371Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from transformers import BertTokenizer, DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n# Load the tokenizer for DistilBERT\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Optionally load the DistilBERT model for sequence classification\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:12:53.655038Z","iopub.execute_input":"2025-03-24T11:12:53.655242Z","iopub.status.idle":"2025-03-24T11:13:12.842290Z","shell.execute_reply.started":"2025-03-24T11:12:53.655224Z","shell.execute_reply":"2025-03-24T11:13:12.841437Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8495f7d0b9f74e1794eefb7754c3c712"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3e9a5d11e4040269f10a283ab2e7766"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b32f66bb7cb4f11843fa0c2f49bccf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad16f67dd78d4bfea42f9ff2dbc10466"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"759716b48e974305938909aeebf77f2e"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Tokenize\ntrain_encodings = tokenizer(list(train_data['caption']), truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(list(valid_data['caption']), truncation=True, padding=True, max_length=512)\ntest_encodings = tokenizer(list(test_data['caption']), truncation=True, padding=True, max_length=512)\n\n# Prepare labels\ntrain_labels = list(train_data['level'])\nval_labels = list(valid_data['level'])\ntest_labels = list(test_data['level'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:13:12.843254Z","iopub.execute_input":"2025-03-24T11:13:12.844038Z","iopub.status.idle":"2025-03-24T11:13:14.374352Z","shell.execute_reply.started":"2025-03-24T11:13:12.844011Z","shell.execute_reply":"2025-03-24T11:13:14.373718Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":" #Create custom dataset class\nclass DisasterDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create datasets\ntrain_dataset = DisasterDataset(train_encodings, train_labels)\nval_dataset = DisasterDataset(val_encodings, val_labels)\ntest_dataset = DisasterDataset(test_encodings, test_labels)\n\n# Load the model\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:13:14.375127Z","iopub.execute_input":"2025-03-24T11:13:14.375368Z","iopub.status.idle":"2025-03-24T11:13:14.799862Z","shell.execute_reply.started":"2025-03-24T11:13:14.375348Z","shell.execute_reply":"2025-03-24T11:13:14.799224Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\nfrom datasets import DatasetDict  # Assuming you are using Hugging Face Datasets\n\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/results',\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",   # Log at the end of every epoch\n    logging_dir='/kaggle/working/logs',\n    logging_steps=10,           # Log every 10 steps\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",       # Save model every epoch\n    logging_first_step=True,\n    load_best_model_at_end=True,\n    report_to=\"none\",            # Avoid WandB logging (useful for Kaggle)\n)\n\n\n# Set up the Trainer\ntrainer = Trainer(\n    model=model,                         # The model to be trained\n    args=training_args,                  # Training arguments\n    train_dataset=train_dataset,         # Training dataset (ensure it's defined)\n    eval_dataset=val_dataset,            # Validation dataset (ensure it's defined)\n)\n\n# Start training\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:13:14.800603Z","iopub.execute_input":"2025-03-24T11:13:14.800832Z","iopub.status.idle":"2025-03-24T11:22:01.774353Z","shell.execute_reply.started":"2025-03-24T11:13:14.800813Z","shell.execute_reply":"2025-03-24T11:22:01.773637Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1040/1040 08:44, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.506600</td>\n      <td>0.319403</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.349400</td>\n      <td>0.233495</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.240600</td>\n      <td>0.322889</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.186000</td>\n      <td>0.239348</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.130800</td>\n      <td>0.254432</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.095500</td>\n      <td>0.250667</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.056200</td>\n      <td>0.303960</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.044200</td>\n      <td>0.303955</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.026400</td>\n      <td>0.309388</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.027900</td>\n      <td>0.318085</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1040, training_loss=0.16654106275393413, metrics={'train_runtime': 526.1923, 'train_samples_per_second': 31.376, 'train_steps_per_second': 1.976, 'total_flos': 2187036751810560.0, 'train_loss': 0.16654106275393413, 'epoch': 10.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\ndef evaluate_model(trainer, eval_dataset):\n    predictions, labels, _ = trainer.predict(eval_dataset)\n    \n    # Convert logits to predicted classes\n    preds = torch.argmax(torch.tensor(predictions), dim=1).numpy()\n    \n    # Compute accuracy\n    accuracy = accuracy_score(labels, preds)\n\n    # Compute precision, recall, and F1 score\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n\n    # Generate classification report\n    report = classification_report(labels, preds, target_names=[\"Class 0\", \"Class 1\"])\n\n    return accuracy, precision, recall, f1, report, labels, preds\n# Evaluate the model on the validation dataset\ntest_accuracy, test_precision, test_recall, test_f1, test_report, all_labels, all_preds = evaluate_model(trainer, val_dataset)\n\n# Print out the results\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {test_precision:.4f}\")\nprint(f\"Test Recall: {test_recall:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")\nprint(\"Classification Report:\\n\", test_report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T11:22:01.775130Z","iopub.execute_input":"2025-03-24T11:22:01.775339Z","iopub.status.idle":"2025-03-24T11:22:05.689221Z","shell.execute_reply.started":"2025-03-24T11:22:01.775321Z","shell.execute_reply":"2025-03-24T11:22:05.688523Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Test Accuracy: 0.9147\nTest Precision: 0.9150\nTest Recall: 0.9147\nTest F1 Score: 0.9148\nClassification Report:\n               precision    recall  f1-score   support\n\n     Class 0       0.88      0.89      0.89       206\n     Class 1       0.94      0.93      0.93       345\n\n    accuracy                           0.91       551\n   macro avg       0.91      0.91      0.91       551\nweighted avg       0.92      0.91      0.91       551\n\n","output_type":"stream"}],"execution_count":11}]}