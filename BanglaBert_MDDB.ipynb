{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11135603,"sourceType":"datasetVersion","datasetId":6945370}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip list | grep \"torch\\|tensorflow\\|transformers\\|opencv\\|scikit-learn\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:03:58.448333Z","iopub.execute_input":"2025-03-27T09:03:58.448739Z","iopub.status.idle":"2025-03-27T09:03:59.744148Z","shell.execute_reply.started":"2025-03-27T09:03:58.448697Z","shell.execute_reply":"2025-03-27T09:03:59.743271Z"}},"outputs":[{"name":"stdout","text":"opencv-contrib-python              4.10.0.84\nopencv-python                      4.10.0.84\nopencv-python-headless             4.10.0.84\npytorch-ignite                     0.5.1\npytorch-lightning                  2.5.0.post0\nscikit-learn                       1.2.2\nscikit-learn-intelex               2025.2.0\nsentence-transformers              3.3.1\ntensorflow                         2.17.1\ntensorflow-cloud                   0.1.5\ntensorflow-datasets                4.9.7\ntensorflow_decision_forests        1.10.0\ntensorflow-hub                     0.16.1\ntensorflow-io                      0.37.1\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.13.1\ntensorflow-probability             0.24.0\ntensorflow-text                    2.17.0\ntorch                              2.5.1+cu121\ntorchaudio                         2.5.1+cu121\ntorchinfo                          1.8.0\ntorchmetrics                       1.6.1\ntorchsummary                       1.5.1\ntorchtune                          0.5.0\ntorchvision                        0.20.1+cu121\ntransformers                       4.47.0\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"!pip install torch torchvision transformers opencv-python scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:03:59.745460Z","iopub.execute_input":"2025-03-27T09:03:59.745715Z","iopub.status.idle":"2025-03-27T09:04:03.706604Z","shell.execute_reply.started":"2025-03-27T09:03:59.745694Z","shell.execute_reply":"2025-03-27T09:04:03.705472Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import os\n\n# Check the dataset directory\n!ls /kaggle/input/multimodal-disaster-dataset-bangla/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.708415Z","iopub.execute_input":"2025-03-27T09:04:03.708768Z","iopub.status.idle":"2025-03-27T09:04:03.905609Z","shell.execute_reply.started":"2025-03-27T09:04:03.708744Z","shell.execute_reply":"2025-03-27T09:04:03.904720Z"}},"outputs":[{"name":"stdout","text":"'Multimodal Disaster Bangla Dataset'\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ncsv_path = '/kaggle/input/multimodal-disaster-dataset-bangla/Multimodal Disaster Bangla Dataset/Thesis.csv'\ndf = pd.read_csv(csv_path,encoding=\"utf-8\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.907295Z","iopub.execute_input":"2025-03-27T09:04:03.907556Z","iopub.status.idle":"2025-03-27T09:04:03.943213Z","shell.execute_reply.started":"2025-03-27T09:04:03.907534Z","shell.execute_reply":"2025-03-27T09:04:03.942435Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"    id                                            caption  label  level  \\\n0    1  ‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...  flood      1   \n1    2  ‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...  flood      1   \n2    3                                           ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ  flood      1   \n3    4  ‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ ‡¶ì ‡¶ï‡¶∏‡¶¨‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ'‡¶∞ ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡ßü ‡¶á...  flood      1   \n4    5  ‡¶´‡ßá‡¶®‡ßÄ‡¶∞ ‡¶Æ‡ßÅ‡¶π‡ßÅ‡¶∞‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶§‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶ó‡¶§ ‡ß™‡ß¶ ‡¶¨‡¶õ‡¶∞‡ßá‡¶∞ ‡¶á‡¶§...  flood      1   \n\n       area Unnamed: 5  \n0  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n1  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n2  ‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ        NaN  \n3   ‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ         NaN  \n4      ‡¶´‡ßá‡¶®‡ßÄ        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>caption</th>\n      <th>label</th>\n      <th>level</th>\n      <th>area</th>\n      <th>Unnamed: 5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>‡¶ó‡ßã‡¶Æ‡¶§‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶™‡¶æ‡¶∂‡ßá ‡¶™‡¶æ‡¶≤‡¶™‡¶æ‡ßú‡¶æ ‡¶Ö‡¶Ç‡¶∂‡ßá ‡¶¨‡¶æ‡¶Å‡¶ß ‡¶•...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶ï‡ßÅ‡¶Æ‡¶ø‡¶≤‡ßç‡¶≤‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ ‡¶ì ‡¶ï‡¶∏‡¶¨‡¶æ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ'‡¶∞ ‡¶¨‡¶ø‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡ßü ‡¶á...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶Ü‡¶ñ‡¶æ‡¶â‡ßú‡¶æ</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>‡¶´‡ßá‡¶®‡ßÄ‡¶∞ ‡¶Æ‡ßÅ‡¶π‡ßÅ‡¶∞‡ßÄ ‡¶®‡¶¶‡ßÄ‡¶§‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡¶æ ‡¶ó‡¶§ ‡ß™‡ß¶ ‡¶¨‡¶õ‡¶∞‡ßá‡¶∞ ‡¶á‡¶§...</td>\n      <td>flood</td>\n      <td>1</td>\n      <td>‡¶´‡ßá‡¶®‡ßÄ</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# Verify column names\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.943906Z","iopub.execute_input":"2025-03-27T09:04:03.944143Z","iopub.status.idle":"2025-03-27T09:04:03.948783Z","shell.execute_reply.started":"2025-03-27T09:04:03.944109Z","shell.execute_reply":"2025-03-27T09:04:03.947681Z"}},"outputs":[{"name":"stdout","text":"Index([' id', 'caption', 'label', 'level', 'area', 'Unnamed: 5'], dtype='object')\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nfrom torchvision import transforms\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.949746Z","iopub.execute_input":"2025-03-27T09:04:03.949945Z","iopub.status.idle":"2025-03-27T09:04:03.968753Z","shell.execute_reply.started":"2025-03-27T09:04:03.949928Z","shell.execute_reply":"2025-03-27T09:04:03.968161Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Drop unnecessary columns if they exist\ncolumns_to_drop = [col for col in ['label', 'area', 'Unnamed: 5'] if col in df.columns]\ndf = df.drop(columns_to_drop, axis=1)\n\n# Shuffle the dataframe\ndf = shuffle(df, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.969510Z","iopub.execute_input":"2025-03-27T09:04:03.969732Z","iopub.status.idle":"2025-03-27T09:04:03.989077Z","shell.execute_reply.started":"2025-03-27T09:04:03.969713Z","shell.execute_reply":"2025-03-27T09:04:03.988335Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"\n# Split the dataset\ntrain_ratio = 0.6\nval_ratio = 0.2\ntest_ratio = 0.2\n\ntrain_data, val_test = train_test_split(df, train_size=train_ratio, random_state=42)\nvalid_data, test_data = train_test_split(val_test, train_size=val_ratio / (val_ratio + test_ratio), random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:03.991867Z","iopub.execute_input":"2025-03-27T09:04:03.992064Z","iopub.status.idle":"2025-03-27T09:04:04.012938Z","shell.execute_reply.started":"2025-03-27T09:04:03.992047Z","shell.execute_reply":"2025-03-27T09:04:04.012026Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = BertTokenizer.from_pretrained('csebuetnlp/banglabert')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:04.013827Z","iopub.execute_input":"2025-03-27T09:04:04.014013Z","iopub.status.idle":"2025-03-27T09:04:04.214491Z","shell.execute_reply.started":"2025-03-27T09:04:04.013997Z","shell.execute_reply":"2025-03-27T09:04:04.213669Z"}},"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, DistilBertForSequenceClassification\n\n# Load the tokenizer for BanglaBERT\ntokenizer = BertTokenizer.from_pretrained('csebuetnlp/banglabert')\n\n# If you want to use BanglaBERT for classification:\nmodel = BertForSequenceClassification.from_pretrained('csebuetnlp/banglabert')\n\n# If you actually wanted DistilBERT, change the tokenizer accordingly:\n# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n# model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:04.215213Z","iopub.execute_input":"2025-03-27T09:04:04.215438Z","iopub.status.idle":"2025-03-27T09:04:05.803839Z","shell.execute_reply.started":"2025-03-27T09:04:04.215416Z","shell.execute_reply":"2025-03-27T09:04:05.802860Z"}},"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\nYou are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Tokenize\ntrain_encodings = tokenizer(list(train_data['caption']), truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(list(valid_data['caption']), truncation=True, padding=True, max_length=512)\ntest_encodings = tokenizer(list(test_data['caption']), truncation=True, padding=True, max_length=512)\n\n# Prepare labels\ntrain_labels = list(train_data['level'])\nval_labels = list(valid_data['level'])\ntest_labels = list(test_data['level'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:05.805505Z","iopub.execute_input":"2025-03-27T09:04:05.805808Z","iopub.status.idle":"2025-03-27T09:04:06.633563Z","shell.execute_reply.started":"2025-03-27T09:04:05.805778Z","shell.execute_reply":"2025-03-27T09:04:06.632626Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"#Create custom dataset class\nclass DisasterDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create datasets\ntrain_dataset = DisasterDataset(train_encodings, train_labels)\nval_dataset = DisasterDataset(val_encodings, val_labels)\ntest_dataset = DisasterDataset(test_encodings, test_labels)\n\n# Load the model\nmodel = BertForSequenceClassification.from_pretrained('csebuetnlp/banglabert', num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:06.634491Z","iopub.execute_input":"2025-03-27T09:04:06.634799Z","iopub.status.idle":"2025-03-27T09:04:07.929978Z","shell.execute_reply.started":"2025-03-27T09:04:06.634765Z","shell.execute_reply":"2025-03-27T09:04:07.929034Z"}},"outputs":[{"name":"stderr","text":"You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\nfrom datasets import DatasetDict  # Assuming you are using Hugging Face Datasets\n\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/results',\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",   # Log at the end of every epoch\n    logging_dir='/kaggle/working/logs',\n    logging_steps=10,           # Log every 10 steps\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",       # Save model every epoch\n    logging_first_step=True,\n    load_best_model_at_end=True,\n    report_to=\"none\",\n)\n\n\n# Set up the Trainer\ntrainer = Trainer(\n    model=model,                         # The model to be trained\n    args=training_args,                  # Training arguments\n    train_dataset=train_dataset,         # Training dataset (ensure it's defined)\n    eval_dataset=val_dataset,            # Validation dataset (ensure it's defined)\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:04:07.931555Z","iopub.execute_input":"2025-03-27T09:04:07.931853Z","iopub.status.idle":"2025-03-27T09:11:26.101519Z","shell.execute_reply.started":"2025-03-27T09:04:07.931828Z","shell.execute_reply":"2025-03-27T09:11:26.100764Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1040/1040 07:16, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.582800</td>\n      <td>0.951933</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.323000</td>\n      <td>0.151202</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.126700</td>\n      <td>0.259709</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.078700</td>\n      <td>0.356360</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.047900</td>\n      <td>0.232554</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.013900</td>\n      <td>0.488279</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.028600</td>\n      <td>0.217151</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.012000</td>\n      <td>0.226646</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.007100</td>\n      <td>0.228804</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000800</td>\n      <td>0.224223</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1040, training_loss=0.1222805719392804, metrics={'train_runtime': 437.2285, 'train_samples_per_second': 37.761, 'train_steps_per_second': 2.379, 'total_flos': 1374457208763600.0, 'train_loss': 0.1222805719392804, 'epoch': 10.0})"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\ndef evaluate_model(trainer, eval_dataset):\n    predictions, labels, _ = trainer.predict(eval_dataset)\n    \n    # Convert logits to predicted classes\n    preds = torch.argmax(torch.tensor(predictions), dim=1).numpy()\n    \n    # Compute accuracy\n    accuracy = accuracy_score(labels, preds)\n\n    # Compute precision, recall, and F1 score\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n    # Generate classification report\n    report = classification_report(labels, preds, target_names=[\"Class 0\", \"Class 1\"])\n\n    return accuracy, precision, recall, f1, report, labels, preds\n# Evaluate the model on the validation dataset\ntest_accuracy, test_precision, test_recall, test_f1, test_report, all_labels, all_preds = evaluate_model(trainer, val_dataset)\n\n# Print out the results\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision: {test_precision:.4f}\")\nprint(f\"Test Recall: {test_recall:.4f}\")\nprint(f\"Test F1 Score: {test_f1:.4f}\")\nprint(\"Classification Report:\\n\", test_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:11:26.102306Z","iopub.execute_input":"2025-03-27T09:11:26.102620Z","iopub.status.idle":"2025-03-27T09:11:28.793462Z","shell.execute_reply.started":"2025-03-27T09:11:26.102588Z","shell.execute_reply":"2025-03-27T09:11:28.792598Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Test Accuracy: 0.9437\nTest Precision: 0.9447\nTest Recall: 0.9437\nTest F1 Score: 0.9440\nClassification Report:\n               precision    recall  f1-score   support\n\n     Class 0       0.91      0.95      0.93       206\n     Class 1       0.97      0.94      0.95       345\n\n    accuracy                           0.94       551\n   macro avg       0.94      0.94      0.94       551\nweighted avg       0.94      0.94      0.94       551\n\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Compute confusion matrix\ncm = confusion_matrix(all_labels, all_preds)\n\n# Plot confusion matrix\nplt.figure(figsize=(5, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Class 0\", \"Class 1\"], yticklabels=[\"Class 0\", \"Class 1\"])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:11:28.794379Z","iopub.execute_input":"2025-03-27T09:11:28.794703Z","iopub.status.idle":"2025-03-27T09:11:28.972536Z","shell.execute_reply.started":"2025-03-27T09:11:28.794662Z","shell.execute_reply":"2025-03-27T09:11:28.971605Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":60}]}