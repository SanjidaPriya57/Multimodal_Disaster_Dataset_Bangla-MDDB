{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11974862,"sourceType":"datasetVersion","datasetId":7530597}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip list | grep \"torch\\|tensorflow\\|transformers\\|opencv\\|scikit-learn\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:03.831383Z","iopub.execute_input":"2025-05-27T20:06:03.832175Z","iopub.status.idle":"2025-05-27T20:06:05.547868Z","shell.execute_reply.started":"2025-05-27T20:06:03.832149Z","shell.execute_reply":"2025-05-27T20:06:05.547108Z"}},"outputs":[{"name":"stdout","text":"opencv-contrib-python              4.11.0.86\nopencv-python                      4.11.0.86\nopencv-python-headless             4.11.0.86\npytorch-ignite                     0.5.2\npytorch-lightning                  2.5.1.post0\nscikit-learn                       1.2.2\nscikit-learn-intelex               2025.5.0\nsentence-transformers              3.4.1\ntensorflow                         2.18.0\ntensorflow-cloud                   0.1.5\ntensorflow-datasets                4.9.8\ntensorflow_decision_forests        1.11.0\ntensorflow-hub                     0.16.1\ntensorflow-io                      0.37.1\ntensorflow-io-gcs-filesystem       0.37.1\ntensorflow-metadata                1.17.0\ntensorflow-probability             0.25.0\ntensorflow-text                    2.18.1\ntorch                              2.6.0+cu124\ntorchao                            0.10.0\ntorchaudio                         2.6.0+cu124\ntorchdata                          0.11.0\ntorchinfo                          1.8.0\ntorchmetrics                       1.7.1\ntorchsummary                       1.5.1\ntorchtune                          0.6.1\ntorchvision                        0.21.0+cu124\ntransformers                       4.51.3\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y fonts-noto","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:05.549368Z","iopub.execute_input":"2025-05-27T20:06:05.549611Z","iopub.status.idle":"2025-05-27T20:06:10.821968Z","shell.execute_reply.started":"2025-05-27T20:06:05.549588Z","shell.execute_reply":"2025-05-27T20:06:10.821112Z"}},"outputs":[{"name":"stdout","text":"Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\nHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease         \nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nHit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease                        \nHit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease                  \nHit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                         \nHit:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease                          \nHit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                                      \nHit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\nHit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nfonts-noto is already the newest version (20201225-1build1).\n0 upgraded, 0 newly installed, 0 to remove and 157 not upgraded.\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"!pip install torch torchvision transformers opencv-python scikit-learn pillow-avif-plugin\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:10.822963Z","iopub.execute_input":"2025-05-27T20:06:10.823258Z","iopub.status.idle":"2025-05-27T20:06:14.098493Z","shell.execute_reply.started":"2025-05-27T20:06:10.823227Z","shell.execute_reply":"2025-05-27T20:06:14.097725Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pillow-avif-plugin in /usr/local/lib/python3.11/dist-packages (1.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\nurl = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTyh006zrmSWoKAwqF92kZ4lvNRKsZL5NYIkdSEK3wtrWA8yMKLT6K3h1k1nyyHjG9ntZvc9tTcbUif/pub?output=csv'\ndf = pd.read_csv(url,encoding=\"utf-8\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:14.100867Z","iopub.execute_input":"2025-05-27T20:06:14.101169Z","iopub.status.idle":"2025-05-27T20:06:15.207538Z","shell.execute_reply.started":"2025-05-27T20:06:14.101141Z","shell.execute_reply":"2025-05-27T20:06:15.206892Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"    id                                            caption  label  level  \\\n0    1  গোমতী নদীর পানি উত্তর পাশে পালপাড়া অংশে বাঁধ থ...  flood    1.0   \n1    2  গোমতী নদীর পানি উত্তর পাশে পালপাড়া অংশে বাঁধ থ...  flood    1.0   \n2    3                                           কুমিল্লা  flood    1.0   \n3    4  আখাউড়া উপজেলা ও কসবা উপজেলা'র বিভিন্ন এলাকায় ই...  flood    1.0   \n4    5  ফেনীর মুহুরী নদীতে পানির মাত্রা গত ৪০ বছরের ইত...  flood    1.0   \n\n       area Unnamed: 5  \n0       NaN        NaN  \n1       NaN        NaN  \n2  কুমিল্লা        NaN  \n3   আখাউড়া         NaN  \n4      ফেনী        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>caption</th>\n      <th>label</th>\n      <th>level</th>\n      <th>area</th>\n      <th>Unnamed: 5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>গোমতী নদীর পানি উত্তর পাশে পালপাড়া অংশে বাঁধ থ...</td>\n      <td>flood</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>গোমতী নদীর পানি উত্তর পাশে পালপাড়া অংশে বাঁধ থ...</td>\n      <td>flood</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>কুমিল্লা</td>\n      <td>flood</td>\n      <td>1.0</td>\n      <td>কুমিল্লা</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>আখাউড়া উপজেলা ও কসবা উপজেলা'র বিভিন্ন এলাকায় ই...</td>\n      <td>flood</td>\n      <td>1.0</td>\n      <td>আখাউড়া</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>ফেনীর মুহুরী নদীতে পানির মাত্রা গত ৪০ বছরের ইত...</td>\n      <td>flood</td>\n      <td>1.0</td>\n      <td>ফেনী</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\nfrom torchvision import transforms\nfrom transformers import BertTokenizer, BertModel\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport os\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.208235Z","iopub.execute_input":"2025-05-27T20:06:15.208467Z","iopub.status.idle":"2025-05-27T20:06:15.213121Z","shell.execute_reply.started":"2025-05-27T20:06:15.208441Z","shell.execute_reply":"2025-05-27T20:06:15.212350Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"# Drop unnecessary columns if they exist\ncolumns_to_drop = [col for col in ['label', 'Unnamed: 5','area'] if col in df.columns]\ndf = df.drop(columns_to_drop, axis=1)\n\n# Shuffle the dataframe\ndf = shuffle(df, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.213943Z","iopub.execute_input":"2025-05-27T20:06:15.214182Z","iopub.status.idle":"2025-05-27T20:06:15.227474Z","shell.execute_reply.started":"2025-05-27T20:06:15.214166Z","shell.execute_reply":"2025-05-27T20:06:15.226725Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"# Remove rows with NaN in 'level' column\ndf = df.dropna(subset=['level'])\ndf['level'] = df['level'].astype(int)  # Ensure labels are integers\nprint(\"Label distribution after removing NaN:\", df['level'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.228301Z","iopub.execute_input":"2025-05-27T20:06:15.228543Z","iopub.status.idle":"2025-05-27T20:06:15.242357Z","shell.execute_reply.started":"2025-05-27T20:06:15.228521Z","shell.execute_reply":"2025-05-27T20:06:15.241703Z"}},"outputs":[{"name":"stdout","text":"Label distribution after removing NaN: level\n1    2660\n0    2519\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"# Split the dataset\ntrain_ratio = 0.6\nval_ratio = 0.2\ntest_ratio = 0.2\n\ntrain_data, val_test = train_test_split(df, train_size=train_ratio, random_state=42)\nvalid_data, test_data = train_test_split(val_test, train_size=val_ratio / (val_ratio + test_ratio), random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.243075Z","iopub.execute_input":"2025-05-27T20:06:15.243351Z","iopub.status.idle":"2025-05-27T20:06:15.256221Z","shell.execute_reply.started":"2025-05-27T20:06:15.243329Z","shell.execute_reply":"2025-05-27T20:06:15.255455Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"train_data.columns = train_data.columns.str.strip()\nvalid_data.columns = valid_data.columns.str.strip()\ntest_data.columns = test_data.columns.str.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.257017Z","iopub.execute_input":"2025-05-27T20:06:15.257697Z","iopub.status.idle":"2025-05-27T20:06:15.261948Z","shell.execute_reply.started":"2025-05-27T20:06:15.257678Z","shell.execute_reply":"2025-05-27T20:06:15.261114Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# Image transformations\nimage_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Load tokenizer and model for text\ntokenizer = BertTokenizer.from_pretrained('csebuetnlp/banglabert')\ntext_model = BertModel.from_pretrained('csebuetnlp/banglabert')\n\n# Load vision model\nvision_model = models.mobilenet_v3_small(pretrained=True)\n# vision_model.eval()  # Set to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:15.264261Z","iopub.execute_input":"2025-05-27T20:06:15.264470Z","iopub.status.idle":"2025-05-27T20:06:16.925919Z","shell.execute_reply.started":"2025-05-27T20:06:15.264455Z","shell.execute_reply":"2025-05-27T20:06:16.925169Z"}},"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\nYou are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertModel were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"# Move models to device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntext_model.to(device)\nvision_model.to(device)\n\nfrom PIL import UnidentifiedImageError\n\n# Feature extraction functions\ndef extract_text_features(dataframe, text_column='caption'):\n    text_features = []\n    text_model.eval()\n    with torch.no_grad():\n        for text in dataframe[text_column]:\n            inputs = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            outputs = text_model(**inputs)\n            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # [CLS] token\n            text_features.append(cls_embedding[0])\n    return np.array(text_features)\n\nfrom PIL import UnidentifiedImageError\n\ndef extract_image_features(dataframe, image_column='id', images_folder='/kaggle/input/d/sanjida57/mddb-images/Photos_Final'):\n    image_features = []\n    vision_model.eval()\n    with torch.no_grad():\n        for image_id in dataframe[image_column]:\n            found_image = False\n            for ext in ['.jpg', '.png', '.jpeg']:\n                image_path = os.path.join(images_folder, f\"{image_id}{ext}\")\n                if os.path.exists(image_path):\n                    try:\n                        image = Image.open(image_path).convert('RGB')\n                        image = image_transforms(image).unsqueeze(0).to(device)\n                        features = vision_model(image).cpu().numpy()\n                        image_features.append(features[0])\n                        found_image = True\n                        break  # stop searching extensions if one works\n                    except UnidentifiedImageError:\n                        print(f\"Cannot identify image file: {image_path}\")\n                        found_image = False\n            if not found_image:\n                print(f\"Image not found or unreadable for ID: {image_id}\")\n                # Append zero vector or handle missing image as you see fit\n                image_features.append(np.zeros(your_feature_size))  # set correct size here\n    return np.array(image_features)\n\n# Extract features\ntrain_text_features = extract_text_features(train_data)\nvalid_text_features = extract_text_features(valid_data)\ntest_text_features = extract_text_features(test_data)\n\ntrain_image_features = extract_image_features(train_data)\nvalid_image_features = extract_image_features(valid_data)\ntest_image_features = extract_image_features(test_data)\n\n# Concatenate features\ntrain_features = np.concatenate([train_text_features, train_image_features], axis=1)\nvalid_features = np.concatenate([valid_text_features, valid_image_features], axis=1)\ntest_features = np.concatenate([test_text_features, test_image_features], axis=1)\n\n# Labels\ntrain_labels = train_data['level'].values\nvalid_labels = valid_data['level'].values\ntest_labels = test_data['level'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:06:16.927113Z","iopub.execute_input":"2025-05-27T20:06:16.927337Z","iopub.status.idle":"2025-05-27T20:09:14.943697Z","shell.execute_reply.started":"2025-05-27T20:06:16.927320Z","shell.execute_reply":"2025-05-27T20:09:14.943098Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# --- Model with regularization and tweaks ---\nxgb_model = XGBClassifier(\n    n_estimators=100,\n    learning_rate=0.05,   # lower learning rate\n    max_depth=3,          # shallower trees\n    reg_lambda=1,         # L2 regularization (default is 1)\n    reg_alpha=0.1,        # L1 regularization\n    subsample=0.8,        # row sampling\n    colsample_bytree=0.8, # feature sampling\n    random_state=42,\n    n_jobs=-1\n)\n\n# --- Train with early stopping ---\nxgb_model.fit(\n    train_features, train_labels,\n    eval_set=[(valid_features, valid_labels)],\n    eval_metric='logloss',\n    early_stopping_rounds=10,  # stop if no improvement in 10 rounds\n    verbose=True\n)\n\n# --- Evaluate ---\n# Training\ntrain_preds_xgb = xgb_model.predict(train_features)\ntrain_acc_xgb = accuracy_score(train_labels, train_preds_xgb)\nprint(\"XGBoost Training Accuracy:\", train_acc_xgb)\n\n# Validation\nvalid_preds_xgb = xgb_model.predict(valid_features)\nvalid_acc_xgb = accuracy_score(valid_labels, valid_preds_xgb)\nprint(\"XGBoost Validation Accuracy:\", valid_acc_xgb)\n\nprint(\"Gap (train - valid):\", train_acc_xgb - valid_acc_xgb)\n\n# Classification reports\nprint(\"\\nValidation Classification Report:\\n\", classification_report(valid_labels, valid_preds_xgb, target_names=['Non Informative', 'Informative']))\n\n# Test set\ntest_preds_xgb = xgb_model.predict(test_features)\ntest_acc_xgb = accuracy_score(test_labels, test_preds_xgb)\nprint(\"\\nTest Accuracy:\", test_acc_xgb)\nprint(\"Test Classification Report:\\n\", classification_report(test_labels, test_preds_xgb, target_names=['Non Informative', 'Informative']))\n\n# Confusion matrix\ncm = confusion_matrix(test_labels, test_preds_xgb, labels=[0, 1])\nprint(\"Confusion Matrix:\\n\", cm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:14.944543Z","iopub.execute_input":"2025-05-27T20:09:14.944759Z","iopub.status.idle":"2025-05-27T20:09:22.438867Z","shell.execute_reply.started":"2025-05-27T20:09:14.944742Z","shell.execute_reply":"2025-05-27T20:09:22.438190Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-logloss:0.66662\n[1]\tvalidation_0-logloss:0.64140\n[2]\tvalidation_0-logloss:0.61675\n[3]\tvalidation_0-logloss:0.59442\n[4]\tvalidation_0-logloss:0.57444\n[5]\tvalidation_0-logloss:0.55594\n[6]\tvalidation_0-logloss:0.53946\n[7]\tvalidation_0-logloss:0.52307\n[8]\tvalidation_0-logloss:0.50782\n[9]\tvalidation_0-logloss:0.49306\n[10]\tvalidation_0-logloss:0.47949\n[11]\tvalidation_0-logloss:0.46831\n[12]\tvalidation_0-logloss:0.45740\n[13]\tvalidation_0-logloss:0.44692\n[14]\tvalidation_0-logloss:0.43729\n[15]\tvalidation_0-logloss:0.42613\n[16]\tvalidation_0-logloss:0.41696\n[17]\tvalidation_0-logloss:0.40906\n[18]\tvalidation_0-logloss:0.40146\n[19]\tvalidation_0-logloss:0.39314\n[20]\tvalidation_0-logloss:0.38604\n[21]\tvalidation_0-logloss:0.37933\n[22]\tvalidation_0-logloss:0.37308\n[23]\tvalidation_0-logloss:0.36738\n[24]\tvalidation_0-logloss:0.36162\n[25]\tvalidation_0-logloss:0.35489\n[26]\tvalidation_0-logloss:0.34899\n[27]\tvalidation_0-logloss:0.34326\n[28]\tvalidation_0-logloss:0.33792\n[29]\tvalidation_0-logloss:0.33302\n[30]\tvalidation_0-logloss:0.32876\n[31]\tvalidation_0-logloss:0.32561\n[32]\tvalidation_0-logloss:0.32113\n[33]\tvalidation_0-logloss:0.31762\n[34]\tvalidation_0-logloss:0.31356\n[35]\tvalidation_0-logloss:0.31010\n[36]\tvalidation_0-logloss:0.30649\n[37]\tvalidation_0-logloss:0.30353\n[38]\tvalidation_0-logloss:0.30106\n[39]\tvalidation_0-logloss:0.29719\n[40]\tvalidation_0-logloss:0.29448\n[41]\tvalidation_0-logloss:0.29165\n[42]\tvalidation_0-logloss:0.28860\n[43]\tvalidation_0-logloss:0.28505\n[44]\tvalidation_0-logloss:0.28196\n[45]\tvalidation_0-logloss:0.27883\n[46]\tvalidation_0-logloss:0.27638\n[47]\tvalidation_0-logloss:0.27378\n[48]\tvalidation_0-logloss:0.27058\n[49]\tvalidation_0-logloss:0.26769\n[50]\tvalidation_0-logloss:0.26557\n[51]\tvalidation_0-logloss:0.26366\n[52]\tvalidation_0-logloss:0.26133\n[53]\tvalidation_0-logloss:0.25921\n[54]\tvalidation_0-logloss:0.25726\n[55]\tvalidation_0-logloss:0.25509\n[56]\tvalidation_0-logloss:0.25288\n[57]\tvalidation_0-logloss:0.25109\n[58]\tvalidation_0-logloss:0.24872\n[59]\tvalidation_0-logloss:0.24637\n[60]\tvalidation_0-logloss:0.24455\n[61]\tvalidation_0-logloss:0.24241\n[62]\tvalidation_0-logloss:0.24077\n[63]\tvalidation_0-logloss:0.23901\n[64]\tvalidation_0-logloss:0.23740\n[65]\tvalidation_0-logloss:0.23570\n[66]\tvalidation_0-logloss:0.23382\n[67]\tvalidation_0-logloss:0.23190\n[68]\tvalidation_0-logloss:0.22994\n[69]\tvalidation_0-logloss:0.22882\n[70]\tvalidation_0-logloss:0.22727\n[71]\tvalidation_0-logloss:0.22574\n[72]\tvalidation_0-logloss:0.22442\n[73]\tvalidation_0-logloss:0.22318\n[74]\tvalidation_0-logloss:0.22176\n[75]\tvalidation_0-logloss:0.22028\n[76]\tvalidation_0-logloss:0.21880\n[77]\tvalidation_0-logloss:0.21785\n[78]\tvalidation_0-logloss:0.21635\n[79]\tvalidation_0-logloss:0.21575\n[80]\tvalidation_0-logloss:0.21461\n[81]\tvalidation_0-logloss:0.21339\n[82]\tvalidation_0-logloss:0.21201\n[83]\tvalidation_0-logloss:0.21073\n[84]\tvalidation_0-logloss:0.20964\n[85]\tvalidation_0-logloss:0.20904\n[86]\tvalidation_0-logloss:0.20778\n[87]\tvalidation_0-logloss:0.20664\n[88]\tvalidation_0-logloss:0.20610\n[89]\tvalidation_0-logloss:0.20519\n[90]\tvalidation_0-logloss:0.20391\n[91]\tvalidation_0-logloss:0.20324\n[92]\tvalidation_0-logloss:0.20243\n[93]\tvalidation_0-logloss:0.20195\n[94]\tvalidation_0-logloss:0.20110\n[95]\tvalidation_0-logloss:0.20056\n[96]\tvalidation_0-logloss:0.19940\n[97]\tvalidation_0-logloss:0.19865\n[98]\tvalidation_0-logloss:0.19820\n[99]\tvalidation_0-logloss:0.19721\nXGBoost Training Accuracy: 0.9629868039909881\nXGBoost Validation Accuracy: 0.9266409266409267\nGap (train - valid): 0.03634587735006145\n\nValidation Classification Report:\n                  precision    recall  f1-score   support\n\nNon Informative       0.93      0.92      0.93       527\n    Informative       0.92      0.93      0.93       509\n\n       accuracy                           0.93      1036\n      macro avg       0.93      0.93      0.93      1036\n   weighted avg       0.93      0.93      0.93      1036\n\n\nTest Accuracy: 0.9411196911196911\nTest Classification Report:\n                  precision    recall  f1-score   support\n\nNon Informative       0.93      0.94      0.94       499\n    Informative       0.95      0.94      0.94       537\n\n       accuracy                           0.94      1036\n      macro avg       0.94      0.94      0.94      1036\n   weighted avg       0.94      0.94      0.94      1036\n\nConfusion Matrix:\n [[471  28]\n [ 33 504]]\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"# from xgboost import XGBClassifier\n# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# # Initialize and train XGBoost\n# xgb_model = XGBClassifier(\n#     n_estimators=100,\n#     learning_rate=0.1,\n#     max_depth=5,\n#     random_state=42,\n#     n_jobs=-1\n# )\n# xgb_model.fit(train_features, train_labels, eval_set=[(valid_features, valid_labels)], eval_metric='logloss', verbose=False)\n\n# # Evaluate on validation set\n# valid_preds = xgb_model.predict(valid_features)\n# print(\"Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\n# print(\"Validation Classification Report:\\n\", classification_report(valid_labels, valid_preds, target_names=['Non Informative', 'Informative']))\n\n# # Evaluate on test set\n# test_preds = xgb_model.predict(test_features)\n# print(\"Test Accuracy:\", accuracy_score(test_labels, test_preds))\n# print(\"Test Classification Report:\\n\", classification_report(test_labels, test_preds, target_names=['Non Informative', 'Informative']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:22.439671Z","iopub.execute_input":"2025-05-27T20:09:22.439867Z","iopub.status.idle":"2025-05-27T20:09:22.443813Z","shell.execute_reply.started":"2025-05-27T20:09:22.439853Z","shell.execute_reply":"2025-05-27T20:09:22.443174Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"\n\nfrom sklearn.svm import SVC\nsvm_model = SVC(kernel='rbf', C=1.0, random_state=42)\nsvm_model.fit(train_features, train_labels)\nvalid_preds = svm_model.predict(valid_features)\ntest_preds = svm_model.predict(test_features)\nprint(\"SVM Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\nprint(\"SVM Test Accuracy:\", accuracy_score(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:22.444609Z","iopub.execute_input":"2025-05-27T20:09:22.444836Z","iopub.status.idle":"2025-05-27T20:09:27.728805Z","shell.execute_reply.started":"2025-05-27T20:09:22.444816Z","shell.execute_reply":"2025-05-27T20:09:27.728121Z"}},"outputs":[{"name":"stdout","text":"SVM Validation Accuracy: 0.946911196911197\nSVM Test Accuracy: 0.9420849420849421\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\nrf_model.fit(train_features, train_labels)\nvalid_preds = rf_model.predict(valid_features)\ntest_preds = rf_model.predict(test_features)\nprint(\"RF Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\nprint(\"RF Test Accuracy:\", accuracy_score(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:27.729727Z","iopub.execute_input":"2025-05-27T20:09:27.730040Z","iopub.status.idle":"2025-05-27T20:09:29.643378Z","shell.execute_reply.started":"2025-05-27T20:09:27.730011Z","shell.execute_reply":"2025-05-27T20:09:29.642587Z"}},"outputs":[{"name":"stdout","text":"RF Validation Accuracy: 0.8928571428571429\nRF Test Accuracy: 0.9044401544401545\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression(max_iter=1000, random_state=42)\nlr_model.fit(train_features, train_labels)\nvalid_preds = lr_model.predict(valid_features)\ntest_preds = lr_model.predict(test_features)\nprint(\"LR Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\nprint(\"LR Test Accuracy:\", accuracy_score(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:29.644230Z","iopub.execute_input":"2025-05-27T20:09:29.644484Z","iopub.status.idle":"2025-05-27T20:09:39.433680Z","shell.execute_reply.started":"2025-05-27T20:09:29.644447Z","shell.execute_reply":"2025-05-27T20:09:39.433074Z"}},"outputs":[{"name":"stdout","text":"LR Validation Accuracy: 0.9372586872586872\nLR Test Accuracy: 0.9459459459459459\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, n_jobs=-1)\nlgbm_model.fit(train_features, train_labels, eval_set=[(valid_features, valid_labels)], eval_metric='logloss')\nvalid_preds = lgbm_model.predict(valid_features)\ntest_preds = lgbm_model.predict(test_features)\nprint(\"LightGBM Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\nprint(\"LightGBM Test Accuracy:\", accuracy_score(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:39.434232Z","iopub.execute_input":"2025-05-27T20:09:39.434439Z","iopub.status.idle":"2025-05-27T20:09:45.629366Z","shell.execute_reply.started":"2025-05-27T20:09:39.434423Z","shell.execute_reply":"2025-05-27T20:09:45.628620Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1614, number of negative: 1493\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082442 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 450840\n[LightGBM] [Info] Number of data points in the train set: 3107, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519472 -> initscore=0.077928\n[LightGBM] [Info] Start training from score 0.077928\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nLightGBM Validation Accuracy: 0.9517374517374517\nLightGBM Test Accuracy: 0.9604247104247104\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"# # (Add feature extraction code from above)\n\n# # Train XGBoost\n# xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, n_jobs=-1)\n# xgb_model.fit(train_features, train_labels, eval_set=[(valid_features, valid_labels)], eval_metric='logloss', verbose=False)\n\n# # Evaluate\n# valid_preds = xgb_model.predict(valid_features)\n# print(\"Validation Accuracy:\", accuracy_score(valid_labels, valid_preds))\n# print(\"Validation Classification Report:\\n\", classification_report(valid_labels, valid_preds, target_names=['Non Informative', 'Informative']))\n\n# test_preds = xgb_model.predict(test_features)\n# print(\"Test Accuracy:\", accuracy_score(test_labels, test_preds))\n# print(\"Test Classification Report:\\n\", classification_report(test_labels, test_preds, target_names=['Non Informative', 'Informative']))\n\n# # Confusion matrix\n# cm = confusion_matrix(test_labels, test_preds, labels=[0, 1])\n# print(\"Confusion Matrix:\\n\", cm)\n\n# # (Add Chart.js code from above)\n\n# cm = confusion_matrix(test_labels, test_preds, labels=[0, 1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:45.630151Z","iopub.execute_input":"2025-05-27T20:09:45.630494Z","iopub.status.idle":"2025-05-27T20:09:45.633678Z","shell.execute_reply.started":"2025-05-27T20:09:45.630477Z","shell.execute_reply":"2025-05-27T20:09:45.633109Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(\"BanglaBERT Parameters:\", count_parameters(text_model))\nprint(\"MobileNetV3-Small Parameters:\", count_parameters(vision_model))\nprint(\"XGBoost Trees:\", xgb_model.n_estimators)\nprint(\"XGBoost Total Nodes:\", sum(len(tree.split('\\n')) for tree in xgb_model.get_booster().get_dump()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:45.634157Z","iopub.execute_input":"2025-05-27T20:09:45.634677Z","iopub.status.idle":"2025-05-27T20:09:45.653655Z","shell.execute_reply.started":"2025-05-27T20:09:45.634658Z","shell.execute_reply":"2025-05-27T20:09:45.652909Z"}},"outputs":[{"name":"stdout","text":"BanglaBERT Parameters: 110617344\nMobileNetV3-Small Parameters: 2542856\nXGBoost Trees: 100\nXGBoost Total Nodes: 1590\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"# Logistic Regression total parameters\ntotal_params_lr = lr_model.coef_.size + lr_model.intercept_.size\nprint(\"Total Logistic Regression Parameters:\", total_params_lr)\n\n# SVM total parameters (if linear kernel)\nif svm_model.kernel == 'linear':\n    total_params_svm = svm_model.coef_.size + svm_model.intercept_.size\n    print(\"Total SVM Parameters:\", total_params_svm)\nelse:\n    print(\"Non-linear SVM kernel. No explicit parameter count.\")\n\n# LightGBM total “parameters” as total nodes\ntotal_nodes_lgb = sum(tree['num_leaves'] for tree in lgbm_model.booster_.dump_model()['tree_info'])\nprint(\"Total LightGBM Nodes (like parameters):\", total_nodes_lgb)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:45.654554Z","iopub.execute_input":"2025-05-27T20:09:45.654773Z","iopub.status.idle":"2025-05-27T20:09:45.716653Z","shell.execute_reply.started":"2025-05-27T20:09:45.654758Z","shell.execute_reply":"2025-05-27T20:09:45.716143Z"}},"outputs":[{"name":"stdout","text":"Total Logistic Regression Parameters: 1769\nNon-linear SVM kernel. No explicit parameter count.\nTotal LightGBM Nodes (like parameters): 2394\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport numpy as np\n\nxgb_cv_scores = cross_val_score(xgb_model, train_features, train_labels, cv=5, scoring='accuracy', n_jobs=-1)\nprint(\"XGBoost 5-Fold CV Accuracy:\", xgb_cv_scores)\nprint(\"Mean CV Accuracy:\", np.mean(xgb_cv_scores))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:09:45.717760Z","iopub.execute_input":"2025-05-27T20:09:45.718377Z","iopub.status.idle":"2025-05-27T20:10:10.023943Z","shell.execute_reply.started":"2025-05-27T20:09:45.718357Z","shell.execute_reply":"2025-05-27T20:10:10.023173Z"}},"outputs":[{"name":"stdout","text":"XGBoost 5-Fold CV Accuracy: [0.92604502 0.90675241 0.9194847  0.90821256 0.91143317]\nMean CV Accuracy: 0.9143855724870683\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"lgbm_cv_scores = cross_val_score(lgbm_model, train_features, train_labels, cv=5, scoring='accuracy', n_jobs=-1)\nprint(\"LightGBM 5-Fold CV Accuracy:\", lgbm_cv_scores)\nprint(\"Mean CV Accuracy:\", np.mean(lgbm_cv_scores))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:10:10.024800Z","iopub.execute_input":"2025-05-27T20:10:10.025061Z","iopub.status.idle":"2025-05-27T20:12:31.309636Z","shell.execute_reply.started":"2025-05-27T20:10:10.025019Z","shell.execute_reply":"2025-05-27T20:12:31.309012Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1291, number of negative: 1194\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236422 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 450840\n[LightGBM] [Info] Number of data points in the train set: 2485, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519517 -> initscore=0.078108\n[LightGBM] [Info] Start training from score 0.078108\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 1291, number of negative: 1195\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123037 seconds.\nYou can set `force_col_wise=true` to remove the overhead.LightGBM 5-Fold CV Accuracy: [0.94051447 0.93247588 0.93075684 0.92914654 0.92109501]\nMean CV Accuracy: 0.9307977486783582\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"# Training Accuracy\ntrain_preds_xgb = xgb_model.predict(train_features)\ntrain_acc_xgb = accuracy_score(train_labels, train_preds_xgb)\nprint(\"XGBoost Training Accuracy:\", train_acc_xgb)\n\n# Validation Accuracy\nvalid_preds_xgb = xgb_model.predict(valid_features)\nvalid_acc_xgb = accuracy_score(valid_labels, valid_preds_xgb)\nprint(\"XGBoost Validation Accuracy:\", valid_acc_xgb)\n\nprint(\"Gap (train - valid):\", train_acc_xgb - valid_acc_xgb)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T20:12:31.310391Z","iopub.execute_input":"2025-05-27T20:12:31.310682Z","iopub.status.idle":"2025-05-27T20:12:31.335473Z","shell.execute_reply.started":"2025-05-27T20:12:31.310664Z","shell.execute_reply":"2025-05-27T20:12:31.334813Z"}},"outputs":[{"name":"stdout","text":"XGBoost Training Accuracy: 0.9629868039909881\nXGBoost Validation Accuracy: 0.9266409266409267\nGap (train - valid): 0.03634587735006145\n[LightGBM] [Info] Number of positive: 1291, number of negative: 1194\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224573 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 450840\n[LightGBM] [Info] Number of data points in the train set: 2485, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519517 -> initscore=0.078108\n[LightGBM] [Info] Start training from score 0.078108\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 1291, number of negative: 1195\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237481 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 450839\n[LightGBM] [Info] Number of data points in the train set: 2486, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519308 -> initscore=0.077271\n[LightGBM] [Info] Start training from score 0.077271\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Number of positive: 1292, number of negative: 1194\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.246856 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 450840\n[LightGBM] [Info] Number of data points in the train set: 2486, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519710 -> initscore=0.078882\n[LightGBM] [Info] Start training from score 0.078882\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n[LightGBM] [Info] Total Bins 450840\n[LightGBM] [Info] Number of data points in the train set: 2486, number of used features: 1768\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519308 -> initscore=0.077271\n[LightGBM] [Info] Start training from score 0.077271\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"}],"execution_count":96}]}